{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0394d2-4168-4f69-aafe-3727ffbbb76c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow==2.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e837c8e4-ec0e-4d38-81dd-b184a510f2b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tempfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = \"columbia-gr5069-main\"\n",
    "\n",
    "# Define a helper to read S3 CSV\n",
    "def read_s3_csv(key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Load datasets from S3\n",
    "results = read_s3_csv(\"raw/results.csv\") #info on rank, fastest lap time and speed\n",
    "races = read_s3_csv(\"raw/races.csv\") #dates and names of all the races but has a lot of empty data\n",
    "drivers = read_s3_csv(\"raw/drivers.csv\") #drivers names and nationalities\n",
    "lap_times = read_s3_csv(\"raw/lap_times.csv\") #for each race, for each driver, the lap time, the number of laps and the time of the fastest lap\n",
    "pit_stops = read_s3_csv(\"raw/pit_stops.csv\") #time spent at the pitstop in each lap\n",
    "qualifying = read_s3_csv(\"raw/qualifying.csv\") #time taken in each round-the ones who dont finish or are disqualified are /N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "180ab428-a0df-4dd2-9b41-532716961593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###want to see what each dataset means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c10a14e7-1e4b-43bc-b767-f9814fced062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "15f042b6-766f-44f7-a2ed-b0898dc53310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display (races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "02b9e9e5-27cf-41e1-81bd-e7807a436f05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "22e7cc6d-e3cc-48d2-aae2-24fe0b9ef1ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(lap_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "296eb208-3d73-43bd-92a5-f379752eb7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(pit_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "402ecde8-c6ea-4240-b349-9592c5985352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(qualifying)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f6102a9-deee-43ae-a5ff-c889ef3453fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preparing dataset by combining results with pitstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "34a33193-1815-4083-9cd5-61f517828923",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1744068890579}",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Reset the index of the results DataFrame\n",
    "results_reset = results.reset_index()\n",
    "\n",
    "# Join results df with pitstops df with suffixes for overlapping columns\n",
    "pitstop_results_df = pit_stops.join(\n",
    "    results_reset.set_index(['raceId', 'driverId']),\n",
    "    on=['raceId', 'driverId'],\n",
    "    how='inner',\n",
    "    lsuffix='_pitstop',\n",
    "    rsuffix='_result'\n",
    ")\n",
    "\n",
    "display(pitstop_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5ed06f6-1d5a-4476-8dc5-b44a4ad59e28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#get a list of all columns in the dataset\n",
    "df = pitstop_results_df.columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f50042d4-0ee0-4214-8981-aebfb0ecb540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "positionOrder: Final race classification (e.g., 1 = winner).\n",
    "\n",
    "rank: Ranking of the driver's fastest lap in the race (e.g., 1 = fastest lap overall).\n",
    "\n",
    "fastestLap: Lap number where the driver set their fastest lap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a527e0f-373c-4377-9953-e7c988cd2493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Objective: I want to predict position order using pitstop_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a68466-1a87-4d4b-837a-d7db2cc2c386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Feature Selection\n",
    "## Using relevant columns from the dataset:\n",
    "\n",
    "### Pre-Race Features:\n",
    "grid (starting position), constructorId (team), driverId (driver skill).\n",
    "\n",
    "### In-Race Features:\n",
    "laps (completed laps), statusId (DNF flag), fastestLapSpeed, fastestLapTime.\n",
    "\n",
    "### Pit Stop Features:\n",
    "stop (number of pit stops), milliseconds_pitstop (total pit time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e4ecbe6-eced-4385-b3a6-b5ad6c09f1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "model_data = pitstop_results_df[['grid','constructorId','raceId','driverId','laps','statusId','fastestLapTime', 'fastestLapSpeed','stop','milliseconds_pitstop','rank','positionOrder']]\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf033716-0877-4bc3-b34d-558da893714c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1af613c-4eb7-4d42-b09c-585098f43320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I'm only interested in those who finsihed the race, so statusId=1 is the only valid metric for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950c27a7-8768-414c-a008-1d8ececfb95e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_data['is_DNF'] = (model_data['statusId'] != 1).astype(int)  # 1=Finished, 0=DNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e3563d-c893-45d1-b7ef-bcd822464ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd8593b-d954-4285-b81b-ac7142168fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#want to check the datatypes and if i have any nans\n",
    "print(model_data.dtypes)\n",
    "print(model_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567f6d96-5838-4598-bda9-57ed1063e27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805cbc10-2867-46b4-a7e1-5de6360554d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df=model_data\n",
    "# Step 1: Replace '\\N' with NaN in problematic columns\n",
    "cols_with_N = [\n",
    "    'grid','constructorId','raceId','driverId','laps','statusId','fastestLapTime', 'fastestLapSpeed','stop','milliseconds_pitstop','rank','positionOrder'\n",
    "]\n",
    "cols_existing = [col for col in cols_with_N if col in model_data.columns]\n",
    "model_data[cols_existing] = model_data[cols_existing].replace('\\\\N', np.nan)\n",
    "\n",
    "# Step 3: Drop non-numeric columns OR encode them if needed\n",
    "df = model_data.select_dtypes(include=[np.number])  \n",
    "\n",
    "# Step 4: Drop remaining rows with missing data \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af99d3de-8264-4264-a889-cf2bb5b04c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Model Prep\n",
    "\n",
    "# Step 5: Define features and target\n",
    "X = df.drop(columns=[\"positionOrder\"])\n",
    "y = df[\"positionOrder\"]\n",
    "\n",
    "# Step 6: Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Step 7: Train model and log with MLflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic RF Experiment\") as run:\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    print(f\"  mse: {mse}\")\n",
    "  \n",
    "    runID = run.info.run_uuid\n",
    "    experimentID = run.info.experiment_id\n",
    "  \n",
    "    print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "252903ed-8b21-429a-a4b2-f06d8e087213",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic RF Experiment\") as run:\n",
    "  # Create model, train it, and create predictions\n",
    "  rf = RandomForestRegressor()\n",
    "  rf.fit(X_train, y_train)\n",
    "  predictions = rf.predict(X_test)\n",
    "  \n",
    "  # Log model\n",
    "  mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "  \n",
    "  # Create metrics\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  print(\"  mse: {}\".format(mse))\n",
    "  \n",
    "  # Log metrics\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  \n",
    "  runID = run.info.run_uuid\n",
    "  experimentID = run.info.experiment_id\n",
    "  \n",
    "  print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e017a6e-e038-44d2-8898-4755c9ab32a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "  import os\n",
    "  import matplotlib.pyplot as plt\n",
    "  import mlflow.sklearn\n",
    "  import seaborn as sns\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "  import tempfile\n",
    "\n",
    "  with mlflow.start_run(experiment_id=experimentID, run_name=run_name) as run:\n",
    "    # Create model, train it, and create predictions\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    # Log params\n",
    "    [mlflow.log_param(param, value) for param, value in params.items()]\n",
    "\n",
    "    # Create metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"  mse: {}\".format(mse))\n",
    "    print(\"  mae: {}\".format(mae))\n",
    "    print(\"  R2: {}\".format(r2))\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"mae\", mae)  \n",
    "    mlflow.log_metric(\"r2\", r2)  \n",
    "    # Create feature importance\n",
    "    importance = pd.DataFrame(list(zip(df.columns, rf.feature_importances_)), \n",
    "                                columns=[\"Feature\", \"Importance\"]\n",
    "                              ).sort_values(\"Importance\", ascending=False)\n",
    "    \n",
    "    # Log importances using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"feature-importance-\", suffix=\".csv\")\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      importance.to_csv(temp_name, index=False)\n",
    "      mlflow.log_artifact(temp_name, \"feature-importance.csv\")\n",
    "    finally:\n",
    "      temp.close() # Delete the temp file\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    sns.residplot(x=predictions, y=y_test, lowess=True, ax=ax)\n",
    "    plt.xlabel(\"Predicted values for PositionOrder\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    # Log residuals using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"residuals-\", suffix=\".png\")\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      fig.savefig(temp_name)\n",
    "      mlflow.log_artifact(temp_name, \"residuals.png\")\n",
    "    finally:\n",
    "      temp.close() # Delete the temp file\n",
    "      \n",
    "    display(fig)\n",
    "    return run.info.run_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f4e974-48bd-41f1-a38e-85d854cd580e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC Run with new parameters.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params1 = {\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": 5,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 1: 100 Estimators, Depth 5\", params1, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params2 = {\n",
    "  \"n_estimators\": 200,\n",
    "  \"max_depth\": 5,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 2: 200 Estimators, Depth 5\", params2, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params3 = {\n",
    "  \"n_estimators\": 300,\n",
    "  \"max_depth\": 5,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 3: 300 Estimators, Depth 5\", params3, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params4 = {\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": 10,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 4: 100 Estimators, Depth 10\", params4, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params5 = {\n",
    "  \"n_estimators\": 200,\n",
    "  \"max_depth\": 10,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 5: 200 Estimators, Depth 10\", params5, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params6 = {\n",
    "  \"n_estimators\": 300,\n",
    "  \"max_depth\": 10,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 6: 300 Estimators, Depth 10\", params6, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params7 = {\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": 15,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 7: 100 Estimators, Depth 15\", params7, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params8 = {\n",
    "  \"n_estimators\": 200,\n",
    "  \"max_depth\": 15,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 8: 200 Estimators, Depth 15\", params8, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params9 = {\n",
    "  \"n_estimators\": 300,\n",
    "  \"max_depth\": 15,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 9: 300 Estimators, Depth 15\", params9, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "params10 = {\n",
    "  \"n_estimators\": 500,\n",
    "  \"max_depth\": 20,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Run 10: 500 Estimators, Depth 20\", params10, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4738edc6-ad52-4005-9c8b-3aa21fa76a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Interpretation:\n",
    "\n",
    "The best model seems to be the last one (10th) which although has the same R2 as models 8,9 and 10 at 0.9 or 90%, but has the least MSE and MAE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Applied Data-HW#3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
